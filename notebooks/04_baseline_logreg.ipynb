{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f610a764-f773-40a8-9946-c811545002e4",
   "metadata": {},
   "source": [
    "### Baseline Logistic Regression\n",
    "- Data: Telco Clean (7,043 rows × 38 features)\n",
    "- Cross‑validation: 5‑fold StratifiedKFold (random_state = 42)\n",
    "- ROC‑AUC (mean ± std): **0.848 ± 0.011**\n",
    "- PR‑AUC (mean ± std): **0.661 ± 0.015**\n",
    "- Parameters: `class_weight='balanced', max_iter=1000`\n",
    "- Model file: `models/logreg.pkl`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "480f1ad3-6644-4893-b8b6-df3955b10171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC‑AUC  : 0.848\n",
      "PR‑AUC   : 0.661\n"
     ]
    }
   ],
   "source": [
    "import joblib, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import RocCurveDisplay, PrecisionRecallDisplay\n",
    "from pathlib import Path\n",
    "\n",
    "THIS_NOTEBOOK = Path.cwd()  \n",
    "PROJECT_ROOT  = THIS_NOTEBOOK.parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "X = joblib.load(DATA_DIR / \"X_train.pkl\")\n",
    "y = joblib.load(DATA_DIR / \"y_train.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "clf = LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
    "\n",
    "scoring = [\"roc_auc\", \"average_precision\"]\n",
    "cv_res = cross_validate(clf, X, y, cv=cv, scoring=scoring, return_estimator=True)\n",
    "\n",
    "print(\"ROC‑AUC  :\", cv_res['test_roc_auc'].mean().round(3))\n",
    "print(\"PR‑AUC   :\", cv_res['test_average_precision'].mean().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50816847-31aa-4252-844d-cd103a4d0db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/pc/churn-prediction-pipeline/models/logreg.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_idx = np.argmax(cv_res[\"test_roc_auc\"])\n",
    "best_clf = cv_res[\"estimator\"][best_idx]\n",
    "best_clf.fit(X, y)\n",
    "\n",
    "\n",
    "import joblib, pathlib as pl\n",
    "pl.Path(PROJECT_ROOT /\"models\").mkdir(exist_ok=True)\n",
    "joblib.dump(best_clf, PROJECT_ROOT /\"models\"/\"logreg.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31410e9a-12a9-4304-b529-178e4b07fe9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC‑AUC  : 0.848 ± 0.011\n",
      "PR‑AUC   : 0.661 ± 0.015\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "roc_mean = cv_res[\"test_roc_auc\"].mean().round(3)   # 0.848\n",
    "roc_std  = cv_res[\"test_roc_auc\"].std(ddof=0).round(3)   # 0.012\n",
    "\n",
    "pr_mean  = cv_res[\"test_average_precision\"].mean().round(3)    # 0.661\n",
    "pr_std   = cv_res[\"test_average_precision\"].std(ddof=0).round(3)    # 0.015\n",
    "\n",
    "print(f\"ROC‑AUC  : {roc_mean} ± {roc_std}\")\n",
    "print(f\"PR‑AUC   : {pr_mean} ± {pr_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbebb8f3-104c-46be-a4e5-ac7c10faaf0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold = 0.59\n",
      "F1  = 0.643\n",
      "Precision = 0.579\n",
      "Recall    = 0.722\n",
      "\n",
      "Classification report @ best threshold\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No-Churn       0.89      0.81      0.85      5174\n",
      "       Churn       0.58      0.72      0.64      1869\n",
      "\n",
      "    accuracy                           0.79      7043\n",
      "   macro avg       0.73      0.77      0.75      7043\n",
      "weighted avg       0.81      0.79      0.79      7043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, f1_score, classification_report\n",
    "\n",
    "proba = best_clf.predict_proba(X)[:, 1]        \n",
    "prec, rec, thr = precision_recall_curve(y, proba)\n",
    "f1 = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "best_idx  = f1.argmax()\n",
    "best_thr  = thr[best_idx]\n",
    "best_f1   = f1[best_idx]\n",
    "best_prec = prec[best_idx]\n",
    "best_rec  = rec[best_idx]\n",
    "\n",
    "print(f\"Best threshold = {best_thr:.2f}\")\n",
    "print(f\"F1  = {best_f1:.3f}\")\n",
    "print(f\"Precision = {best_prec:.3f}\")\n",
    "print(f\"Recall    = {best_rec:.3f}\")\n",
    "\n",
    "# 便于核验\n",
    "y_pred = (proba >= best_thr).astype(int)\n",
    "print(\"\\nClassification report @ best threshold\\n\")\n",
    "print(classification_report(y, y_pred, target_names=[\"No-Churn\", \"Churn\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (churn-env)",
   "language": "python",
   "name": "churn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
